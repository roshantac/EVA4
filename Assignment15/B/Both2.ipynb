{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshantac/EVA4/blob/master/Assignment15/B/Both2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qquZYzsvaLyz",
        "colab_type": "code",
        "outputId": "2d78385d-a1f0-49c1-ff34-0f39ed82fa62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tue May 19 14:37:08 2020       ',\n",
              " '+-----------------------------------------------------------------------------+',\n",
              " '| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |',\n",
              " '|-------------------------------+----------------------+----------------------+',\n",
              " '| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |',\n",
              " '| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |',\n",
              " '|===============================+======================+======================|',\n",
              " '|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |',\n",
              " '| N/A   54C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |',\n",
              " '+-------------------------------+----------------------+----------------------+',\n",
              " '                                                                               ',\n",
              " '+-----------------------------------------------------------------------------+',\n",
              " '| Processes:                                                       GPU Memory |',\n",
              " '|  GPU       PID   Type   Process name                             Usage      |',\n",
              " '|=============================================================================|',\n",
              " '|  No running processes found                                                 |',\n",
              " '+-----------------------------------------------------------------------------+']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz41fo52a-Np",
        "colab_type": "code",
        "outputId": "5f07899c-7735-495a-e540-9a8a990b3494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/roshantac/Unet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Unet'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/51)\u001b[K\rremote: Counting objects:   3% (2/51)\u001b[K\rremote: Counting objects:   5% (3/51)\u001b[K\rremote: Counting objects:   7% (4/51)\u001b[K\rremote: Counting objects:   9% (5/51)\u001b[K\rremote: Counting objects:  11% (6/51)\u001b[K\rremote: Counting objects:  13% (7/51)\u001b[K\rremote: Counting objects:  15% (8/51)\u001b[K\rremote: Counting objects:  17% (9/51)\u001b[K\rremote: Counting objects:  19% (10/51)\u001b[K\rremote: Counting objects:  21% (11/51)\u001b[K\rremote: Counting objects:  23% (12/51)\u001b[K\rremote: Counting objects:  25% (13/51)\u001b[K\rremote: Counting objects:  27% (14/51)\u001b[K\rremote: Counting objects:  29% (15/51)\u001b[K\rremote: Counting objects:  31% (16/51)\u001b[K\rremote: Counting objects:  33% (17/51)\u001b[K\rremote: Counting objects:  35% (18/51)\u001b[K\rremote: Counting objects:  37% (19/51)\u001b[K\rremote: Counting objects:  39% (20/51)\u001b[K\rremote: Counting objects:  41% (21/51)\u001b[K\rremote: Counting objects:  43% (22/51)\u001b[K\rremote: Counting objects:  45% (23/51)\u001b[K\rremote: Counting objects:  47% (24/51)\u001b[K\rremote: Counting objects:  49% (25/51)\u001b[K\rremote: Counting objects:  50% (26/51)\u001b[K\rremote: Counting objects:  52% (27/51)\u001b[K\rremote: Counting objects:  54% (28/51)\u001b[K\rremote: Counting objects:  56% (29/51)\u001b[K\rremote: Counting objects:  58% (30/51)\u001b[K\rremote: Counting objects:  60% (31/51)\u001b[K\rremote: Counting objects:  62% (32/51)\u001b[K\rremote: Counting objects:  64% (33/51)\u001b[K\rremote: Counting objects:  66% (34/51)\u001b[K\rremote: Counting objects:  68% (35/51)\u001b[K\rremote: Counting objects:  70% (36/51)\u001b[K\rremote: Counting objects:  72% (37/51)\u001b[K\rremote: Counting objects:  74% (38/51)\u001b[K\rremote: Counting objects:  76% (39/51)\u001b[K\rremote: Counting objects:  78% (40/51)\u001b[K\rremote: Counting objects:  80% (41/51)\u001b[K\rremote: Counting objects:  82% (42/51)\u001b[K\rremote: Counting objects:  84% (43/51)\u001b[K\rremote: Counting objects:  86% (44/51)\u001b[K\rremote: Counting objects:  88% (45/51)\u001b[K\rremote: Counting objects:  90% (46/51)\u001b[K\rremote: Counting objects:  92% (47/51)\u001b[K\rremote: Counting objects:  94% (48/51)\u001b[K\rremote: Counting objects:  96% (49/51)\u001b[K\rremote: Counting objects:  98% (50/51)\u001b[K\rremote: Counting objects: 100% (51/51)\u001b[K\rremote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 51 (delta 20), reused 30 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXRBXDB8u5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Unet/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONDvNBUxbxh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "28579f24-ccd4-44cd-f3b8-622ec4736e15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwh6CNzBbIr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir temp\n",
        "!cp '/content/drive/My Drive/Rohit dataset/Dataset.zip' temp\n",
        "#!cp '/content/drive/My Drive/sample10.zip' temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TChDfT0a9LiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "destDataDir = '/content/temp/'\n",
        "path_to_zip_file = '/content/temp/Dataset.zip'\n",
        "import zipfile\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destDataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKHTqk8_aX9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"/content/temp/label_data.csv\", \"r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j490X_OfhSuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = f.readlines()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXiyzRTHju0V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4dc53a8-43e9-4413-8eca-9ef34620fccb"
      },
      "source": [
        "print(len(data))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXukhVXphq4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fae9ef69-9ab1-4cdc-cf22-ecfc69e11f81"
      },
      "source": [
        "ds = data[0].split(';')\n",
        "print(ds)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\"Dataset/bg/bg80.jpg\"', '\"Dataset/bg80/fg_91/overlay/1.jpg\"', '\"Dataset/bg80/fg_91/mask/1.jpg\"', '\"Dataset/bg80/fg_91/depth/1.jpg\"\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki9jpkZWh_AI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "de1a8f00-bd4e-44a5-dc7d-e6dc71e620db"
      },
      "source": [
        "print(ds[3])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Dataset/bg80/fg_91/depth/1.jpg\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62H6lDF_kFRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "86bbd3c9-9c62-4b01-8f80-9df2210d3774"
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Dataset/bg80/fg_91/depth/1.jpg\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apshms5SiRzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tglB2BKcakLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "f6665adf-2cf8-4424-8ced-2a63ee1dd873"
      },
      "source": [
        "ds"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of        Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overlay/1.jpg\";\"Dataset/bg80/fg_91/mask/1.jpg\";\"Dataset/bg80/fg_91/depth/1.jpg\"\n",
              "0       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "1       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "2       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "3       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "4       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "...                                                   ...                                                                     \n",
              "399994  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "399995  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "399996  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "399997  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "399998  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "\n",
              "[399999 rows x 1 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD8WKmM2dVQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7fae28e9-ea65-47b3-9d77-a433bd43afac"
      },
      "source": [
        "ds.info"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of        Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overlay/1.jpg\";\"Dataset/bg80/fg_91/mask/1.jpg\";\"Dataset/bg80/fg_91/depth/1.jpg\"\n",
              "0       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "1       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "2       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "3       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "4       Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overla...                                                                     \n",
              "...                                                   ...                                                                     \n",
              "399994  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "399995  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "399996  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "399997  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "399998  Dataset/bg/bg34.jpg;\"Dataset/bg34/fg_4/overlay...                                                                     \n",
              "\n",
              "[399999 rows x 1 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkGl0qvxcqxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be4e798a-fe86-4caf-e657-80172405cfe8"
      },
      "source": [
        "ds.loc[0][0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dataset/bg/bg80.jpg;\"Dataset/bg80/fg_91/overlay/2.jpg\";\"Dataset/bg80/fg_91/mask/2.jpg\";\"Dataset/bg80/fg_91/depth/2.jpg\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH2CTv60df1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e805d411-8e79-4910-b95c-00267a87fa8e"
      },
      "source": [
        "ds.loc[1,1]\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e80b562e17f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1419\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m                 \u001b[0;31m# This is an elided recursive call to iloc/loc/etc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not applicable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1831\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# a scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   2885\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"loc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2887\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_invalid_indexer\u001b[0;34m(self, form, key)\u001b[0m\n\u001b[1;32m   3074\u001b[0m         \"\"\"\n\u001b[1;32m   3075\u001b[0m         raise TypeError(\n\u001b[0;32m-> 3076\u001b[0;31m             \u001b[0;34mf\"cannot do {form} indexing on {type(self)} with these \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3077\u001b[0m             \u001b[0;34mf\"indexers [{key}] of {type(key)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot do label indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [1] of <class 'int'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDQg9tG_c4Vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# destDataDir = '/content/temp/'\n",
        "# path_to_zip_file = '/content/temp/sample10.zip'\n",
        "# import zipfile\n",
        "# with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(destDataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyi6tClyd8LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv '/content/temp/sample10k/depth' '/content/Unet/data/'\n",
        "!mv '/content/temp/sample10k/fgbg' '/content/Unet/data/'\n",
        "!mv '/content/temp/sample10k/mask' '/content/Unet/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e4dVW1mfJJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urmqrDaqfzDE",
        "colab_type": "code",
        "outputId": "8b2cd6b9-8c42-4748-bfbb-db0ebea27852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd Unet/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Unet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dq22dgZ-777",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "from eval import eval_net\n",
        "from unet import UNet\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from utils.dataset import BasicDataset\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx-6s2yD-2Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_img = 'data/fgbg/'\n",
        "dir_mask = 'data/mask/'\n",
        "dir_depth =  'data/depth/'\n",
        "dir_checkpoint = 'checkpoints/'\n",
        "\n",
        "def train_net(net, device, epochs = 10, batch_size = 1, lr = 0.001, val_percent  =0.2, save_cp = True, img_scale = 0.5):\n",
        "    dataset = BasicDataset(dir_img, dir_mask, dir_depth, img_scale)\n",
        "    n_val = int(len(dataset) * val_percent)\n",
        "    n_train = len(dataset) - n_val\n",
        "    train, val = random_split(dataset, [n_train, n_val])\n",
        "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
        "\n",
        "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{img_scale}')\n",
        "    global_step = 0\n",
        "\n",
        "    logging.info(f'''Starting training:\n",
        "        Epochs:          {epochs}\n",
        "        Batch size:      {batch_size}\n",
        "        Learning rate:   {lr}\n",
        "        Training size:   {n_train}\n",
        "        Validation size: {n_val}\n",
        "        Checkpoints:     {save_cp}\n",
        "        Device:          {device.type}\n",
        "        Images scaling:  {img_scale}\n",
        "    ''')\n",
        "\n",
        "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)\n",
        "    if net.n_classes > 1:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "\n",
        "        epoch_loss = 0\n",
        "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
        "            for batch in train_loader:\n",
        "                imgs = batch['image']\n",
        "                true_masks = batch['mask']\n",
        "                true_depth = batch['depth'] #------------------------add----------------\n",
        "                assert imgs.shape[1] == net.n_channels, \\\n",
        "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
        "                    f'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
        "                    'the images are loaded correctly.'\n",
        "\n",
        "                imgs = imgs.to(device=device, dtype=torch.float32)\n",
        "                mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
        "                true_masks = true_masks.to(device=device, dtype=mask_type)\n",
        "                true_depth = true_depth.to(device=device, dtype=torch.float32) #------------------------add----------------\n",
        "\n",
        "                depth_pred, masks_pred = net(imgs)\n",
        "                loss1 = criterion(masks_pred, true_masks)\n",
        "                loss2 = criterion(depth_pred, true_depth) #------------------------add----------------\n",
        "                loss = loss1 + loss2 #------------------------add----------------\n",
        "                epoch_loss += loss.item()\n",
        "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
        "\n",
        "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
        "                optimizer.step()\n",
        "\n",
        "                pbar.update(imgs.shape[0])\n",
        "                global_step += 1\n",
        "                # if global_step % (len(dataset) // (10 * batch_size)) == 0:\n",
        "                #     for tag, value in net.named_parameters():\n",
        "                #         tag = tag.replace('.', '/')\n",
        "                #         writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
        "                #         writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
        "                #     val_score = eval_net(net, val_loader, device)\n",
        "                #     scheduler.step(val_score)\n",
        "                #     writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
        "\n",
        "                #     if net.n_classes > 1:\n",
        "                #         logging.info('Validation cross entropy: {}'.format(val_score))\n",
        "                #         writer.add_scalar('Loss/test', val_score, global_step)\n",
        "                #     else:\n",
        "                #         logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
        "                #         writer.add_scalar('Dice/test', val_score, global_step)\n",
        "\n",
        "                #     writer.add_images('images', imgs, global_step)\n",
        "                #     if net.n_classes == 1:\n",
        "                #         writer.add_images('masks/true', true_masks, global_step)\n",
        "                #         writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
        "\n",
        "        if save_cp:\n",
        "            try:\n",
        "                os.mkdir(dir_checkpoint)\n",
        "                logging.info('Created checkpoint directory')\n",
        "            except OSError:\n",
        "                pass\n",
        "            torch.save(net.state_dict(),\n",
        "                       dir_checkpoint + f'CP_epoch{epoch + 1}.pth')\n",
        "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
        "\n",
        "    writer.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3unl_YZQGz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = UNet(n_channels=3, n_classes=1, bilinear=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sqw9aCdQHVa",
        "colab_type": "code",
        "outputId": "7a6724be-6a87-4e7a-edcf-3ea10f7fa3cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device=device)\n",
        "summary(net, (3,200,200))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 200, 200]             896\n",
            "       BatchNorm2d-2         [-1, 32, 200, 200]              64\n",
            "              ReLU-3         [-1, 32, 200, 200]               0\n",
            "            Conv2d-4         [-1, 32, 200, 200]           9,248\n",
            "       BatchNorm2d-5         [-1, 32, 200, 200]              64\n",
            "              ReLU-6         [-1, 32, 200, 200]               0\n",
            "        DoubleConv-7         [-1, 32, 200, 200]               0\n",
            "         MaxPool2d-8         [-1, 32, 100, 100]               0\n",
            "            Conv2d-9         [-1, 64, 100, 100]          18,496\n",
            "      BatchNorm2d-10         [-1, 64, 100, 100]             128\n",
            "             ReLU-11         [-1, 64, 100, 100]               0\n",
            "           Conv2d-12         [-1, 64, 100, 100]          36,928\n",
            "      BatchNorm2d-13         [-1, 64, 100, 100]             128\n",
            "             ReLU-14         [-1, 64, 100, 100]               0\n",
            "       DoubleConv-15         [-1, 64, 100, 100]               0\n",
            "             Down-16         [-1, 64, 100, 100]               0\n",
            "        MaxPool2d-17           [-1, 64, 50, 50]               0\n",
            "           Conv2d-18          [-1, 128, 50, 50]          73,856\n",
            "      BatchNorm2d-19          [-1, 128, 50, 50]             256\n",
            "             ReLU-20          [-1, 128, 50, 50]               0\n",
            "           Conv2d-21          [-1, 128, 50, 50]         147,584\n",
            "      BatchNorm2d-22          [-1, 128, 50, 50]             256\n",
            "             ReLU-23          [-1, 128, 50, 50]               0\n",
            "       DoubleConv-24          [-1, 128, 50, 50]               0\n",
            "             Down-25          [-1, 128, 50, 50]               0\n",
            "        MaxPool2d-26          [-1, 128, 25, 25]               0\n",
            "           Conv2d-27          [-1, 256, 25, 25]         295,168\n",
            "      BatchNorm2d-28          [-1, 256, 25, 25]             512\n",
            "             ReLU-29          [-1, 256, 25, 25]               0\n",
            "           Conv2d-30          [-1, 256, 25, 25]         590,080\n",
            "      BatchNorm2d-31          [-1, 256, 25, 25]             512\n",
            "             ReLU-32          [-1, 256, 25, 25]               0\n",
            "       DoubleConv-33          [-1, 256, 25, 25]               0\n",
            "             Down-34          [-1, 256, 25, 25]               0\n",
            "        MaxPool2d-35          [-1, 256, 12, 12]               0\n",
            "           Conv2d-36          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-37          [-1, 256, 12, 12]             512\n",
            "             ReLU-38          [-1, 256, 12, 12]               0\n",
            "           Conv2d-39          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-40          [-1, 256, 12, 12]             512\n",
            "             ReLU-41          [-1, 256, 12, 12]               0\n",
            "       DoubleConv-42          [-1, 256, 12, 12]               0\n",
            "             Down-43          [-1, 256, 12, 12]               0\n",
            "         Upsample-44          [-1, 256, 24, 24]               0\n",
            "           Conv2d-45          [-1, 256, 25, 25]       1,179,904\n",
            "      BatchNorm2d-46          [-1, 256, 25, 25]             512\n",
            "             ReLU-47          [-1, 256, 25, 25]               0\n",
            "           Conv2d-48          [-1, 128, 25, 25]         295,040\n",
            "      BatchNorm2d-49          [-1, 128, 25, 25]             256\n",
            "             ReLU-50          [-1, 128, 25, 25]               0\n",
            "       DoubleConv-51          [-1, 128, 25, 25]               0\n",
            "               Up-52          [-1, 128, 25, 25]               0\n",
            "         Upsample-53          [-1, 128, 50, 50]               0\n",
            "           Conv2d-54          [-1, 128, 50, 50]         295,040\n",
            "      BatchNorm2d-55          [-1, 128, 50, 50]             256\n",
            "             ReLU-56          [-1, 128, 50, 50]               0\n",
            "           Conv2d-57           [-1, 64, 50, 50]          73,792\n",
            "      BatchNorm2d-58           [-1, 64, 50, 50]             128\n",
            "             ReLU-59           [-1, 64, 50, 50]               0\n",
            "       DoubleConv-60           [-1, 64, 50, 50]               0\n",
            "               Up-61           [-1, 64, 50, 50]               0\n",
            "         Upsample-62         [-1, 64, 100, 100]               0\n",
            "           Conv2d-63         [-1, 64, 100, 100]          73,792\n",
            "      BatchNorm2d-64         [-1, 64, 100, 100]             128\n",
            "             ReLU-65         [-1, 64, 100, 100]               0\n",
            "           Conv2d-66         [-1, 32, 100, 100]          18,464\n",
            "      BatchNorm2d-67         [-1, 32, 100, 100]              64\n",
            "             ReLU-68         [-1, 32, 100, 100]               0\n",
            "       DoubleConv-69         [-1, 32, 100, 100]               0\n",
            "               Up-70         [-1, 32, 100, 100]               0\n",
            "         Upsample-71         [-1, 32, 200, 200]               0\n",
            "           Conv2d-72         [-1, 32, 200, 200]          18,464\n",
            "      BatchNorm2d-73         [-1, 32, 200, 200]              64\n",
            "             ReLU-74         [-1, 32, 200, 200]               0\n",
            "           Conv2d-75         [-1, 32, 200, 200]           9,248\n",
            "      BatchNorm2d-76         [-1, 32, 200, 200]              64\n",
            "             ReLU-77         [-1, 32, 200, 200]               0\n",
            "       DoubleConv-78         [-1, 32, 200, 200]               0\n",
            "               Up-79         [-1, 32, 200, 200]               0\n",
            "           Conv2d-80          [-1, 1, 200, 200]              33\n",
            "          OutConv-81          [-1, 1, 200, 200]               0\n",
            "           Conv2d-82         [-1, 32, 200, 200]             896\n",
            "      BatchNorm2d-83         [-1, 32, 200, 200]              64\n",
            "             ReLU-84         [-1, 32, 200, 200]               0\n",
            "           Conv2d-85         [-1, 32, 200, 200]           9,248\n",
            "      BatchNorm2d-86         [-1, 32, 200, 200]              64\n",
            "             ReLU-87         [-1, 32, 200, 200]               0\n",
            "       DoubleConv-88         [-1, 32, 200, 200]               0\n",
            "        MaxPool2d-89         [-1, 32, 100, 100]               0\n",
            "           Conv2d-90         [-1, 64, 100, 100]          18,496\n",
            "      BatchNorm2d-91         [-1, 64, 100, 100]             128\n",
            "             ReLU-92         [-1, 64, 100, 100]               0\n",
            "           Conv2d-93         [-1, 64, 100, 100]          36,928\n",
            "      BatchNorm2d-94         [-1, 64, 100, 100]             128\n",
            "             ReLU-95         [-1, 64, 100, 100]               0\n",
            "       DoubleConv-96         [-1, 64, 100, 100]               0\n",
            "             Down-97         [-1, 64, 100, 100]               0\n",
            "        MaxPool2d-98           [-1, 64, 50, 50]               0\n",
            "           Conv2d-99          [-1, 128, 50, 50]          73,856\n",
            "     BatchNorm2d-100          [-1, 128, 50, 50]             256\n",
            "            ReLU-101          [-1, 128, 50, 50]               0\n",
            "          Conv2d-102          [-1, 128, 50, 50]         147,584\n",
            "     BatchNorm2d-103          [-1, 128, 50, 50]             256\n",
            "            ReLU-104          [-1, 128, 50, 50]               0\n",
            "      DoubleConv-105          [-1, 128, 50, 50]               0\n",
            "            Down-106          [-1, 128, 50, 50]               0\n",
            "       MaxPool2d-107          [-1, 128, 25, 25]               0\n",
            "          Conv2d-108          [-1, 256, 25, 25]         295,168\n",
            "     BatchNorm2d-109          [-1, 256, 25, 25]             512\n",
            "            ReLU-110          [-1, 256, 25, 25]               0\n",
            "          Conv2d-111          [-1, 256, 25, 25]         590,080\n",
            "     BatchNorm2d-112          [-1, 256, 25, 25]             512\n",
            "            ReLU-113          [-1, 256, 25, 25]               0\n",
            "      DoubleConv-114          [-1, 256, 25, 25]               0\n",
            "            Down-115          [-1, 256, 25, 25]               0\n",
            "       MaxPool2d-116          [-1, 256, 12, 12]               0\n",
            "          Conv2d-117          [-1, 256, 12, 12]         590,080\n",
            "     BatchNorm2d-118          [-1, 256, 12, 12]             512\n",
            "            ReLU-119          [-1, 256, 12, 12]               0\n",
            "          Conv2d-120          [-1, 256, 12, 12]         590,080\n",
            "     BatchNorm2d-121          [-1, 256, 12, 12]             512\n",
            "            ReLU-122          [-1, 256, 12, 12]               0\n",
            "      DoubleConv-123          [-1, 256, 12, 12]               0\n",
            "            Down-124          [-1, 256, 12, 12]               0\n",
            "        Upsample-125          [-1, 256, 24, 24]               0\n",
            "          Conv2d-126          [-1, 256, 25, 25]       1,179,904\n",
            "     BatchNorm2d-127          [-1, 256, 25, 25]             512\n",
            "            ReLU-128          [-1, 256, 25, 25]               0\n",
            "          Conv2d-129          [-1, 128, 25, 25]         295,040\n",
            "     BatchNorm2d-130          [-1, 128, 25, 25]             256\n",
            "            ReLU-131          [-1, 128, 25, 25]               0\n",
            "      DoubleConv-132          [-1, 128, 25, 25]               0\n",
            "              Up-133          [-1, 128, 25, 25]               0\n",
            "        Upsample-134          [-1, 128, 50, 50]               0\n",
            "          Conv2d-135          [-1, 128, 50, 50]         295,040\n",
            "     BatchNorm2d-136          [-1, 128, 50, 50]             256\n",
            "            ReLU-137          [-1, 128, 50, 50]               0\n",
            "          Conv2d-138           [-1, 64, 50, 50]          73,792\n",
            "     BatchNorm2d-139           [-1, 64, 50, 50]             128\n",
            "            ReLU-140           [-1, 64, 50, 50]               0\n",
            "      DoubleConv-141           [-1, 64, 50, 50]               0\n",
            "              Up-142           [-1, 64, 50, 50]               0\n",
            "        Upsample-143         [-1, 64, 100, 100]               0\n",
            "          Conv2d-144         [-1, 64, 100, 100]          73,792\n",
            "     BatchNorm2d-145         [-1, 64, 100, 100]             128\n",
            "            ReLU-146         [-1, 64, 100, 100]               0\n",
            "          Conv2d-147         [-1, 32, 100, 100]          18,464\n",
            "     BatchNorm2d-148         [-1, 32, 100, 100]              64\n",
            "            ReLU-149         [-1, 32, 100, 100]               0\n",
            "      DoubleConv-150         [-1, 32, 100, 100]               0\n",
            "              Up-151         [-1, 32, 100, 100]               0\n",
            "        Upsample-152         [-1, 32, 200, 200]               0\n",
            "          Conv2d-153         [-1, 32, 200, 200]          18,464\n",
            "     BatchNorm2d-154         [-1, 32, 200, 200]              64\n",
            "            ReLU-155         [-1, 32, 200, 200]               0\n",
            "          Conv2d-156         [-1, 32, 200, 200]           9,248\n",
            "     BatchNorm2d-157         [-1, 32, 200, 200]              64\n",
            "            ReLU-158         [-1, 32, 200, 200]               0\n",
            "      DoubleConv-159         [-1, 32, 200, 200]               0\n",
            "              Up-160         [-1, 32, 200, 200]               0\n",
            "          Conv2d-161          [-1, 1, 200, 200]              33\n",
            "         OutConv-162          [-1, 1, 200, 200]               0\n",
            "================================================================\n",
            "Total params: 8,641,218\n",
            "Trainable params: 8,641,218\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.46\n",
            "Forward/backward pass size (MB): 574.94\n",
            "Params size (MB): 32.96\n",
            "Estimated Total Size (MB): 608.36\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOogjh1fQtf",
        "colab_type": "code",
        "outputId": "09d14eac-2964-46be-bf96-c539f44bfd5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
        "\n",
        "logging.info(f'Using device {device}')\n",
        "\n",
        "# Change here to adapt to your data\n",
        "# n_channels=3 for RGB images\n",
        "# n_classes is the number of probabilities you want to get per pixel\n",
        "#   - For 1 class and background, use n_classes=1\n",
        "#   - For 2 classes, use n_classes=1\n",
        "#   - For N > 2 classes, use n_classes=N\n",
        "\n",
        "logging.info(f'Network:\\n'\n",
        "              f'\\t{net.n_channels} input channels\\n'\n",
        "              f'\\t{net.n_classes} output channels (classes)\\n'\n",
        "              f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
        "\n",
        "\n",
        "# faster convolutions, but more \n",
        "#memorycudnn.benchmark = True\n",
        "train_net(net=net,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          lr=0.001,\n",
        "          device=device,\n",
        "          img_scale=1.0,\n",
        "          val_percent= 10.0/ 100)\n",
        "# except KeyboardInterrupt:\n",
        "#     torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
        "#     logging.info('Saved interrupt')\n",
        "#     try:\n",
        "#         sys.exit(0)\n",
        "#     except SystemExit:\n",
        "#         os._exit(0)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Using device cuda\n",
            "INFO: Network:\n",
            "\t3 input channels\n",
            "\t1 output channels (classes)\n",
            "\tBilinear upscaling\n",
            "INFO: Starting training:\n",
            "        Epochs:          10\n",
            "        Batch size:      32\n",
            "        Learning rate:   0.001\n",
            "        Training size:   9000\n",
            "        Validation size: 1000\n",
            "        Checkpoints:     True\n",
            "        Device:          cuda\n",
            "        Images scaling:  1.0\n",
            "    \n",
            "Epoch 1/10: 100%|██████████| 9000/9000 [02:09<00:00, 69.37img/s, loss (batch)=1.25]\n",
            "INFO: Checkpoint 1 saved !\n",
            "Epoch 2/10: 100%|██████████| 9000/9000 [02:08<00:00, 69.79img/s, loss (batch)=1.17]\n",
            "INFO: Checkpoint 2 saved !\n",
            "Epoch 3/10: 100%|██████████| 9000/9000 [02:08<00:00, 69.77img/s, loss (batch)=1.13]\n",
            "INFO: Checkpoint 3 saved !\n",
            "Epoch 4/10: 100%|██████████| 9000/9000 [02:08<00:00, 69.80img/s, loss (batch)=1.19]\n",
            "INFO: Checkpoint 4 saved !\n",
            "Epoch 5/10: 100%|██████████| 9000/9000 [02:09<00:00, 69.68img/s, loss (batch)=1.15]\n",
            "INFO: Checkpoint 5 saved !\n",
            "Epoch 6/10: 100%|██████████| 9000/9000 [02:09<00:00, 69.68img/s, loss (batch)=1.17]\n",
            "INFO: Checkpoint 6 saved !\n",
            "Epoch 7/10: 100%|██████████| 9000/9000 [02:08<00:00, 69.86img/s, loss (batch)=1.15]\n",
            "INFO: Checkpoint 7 saved !\n",
            "Epoch 8/10: 100%|██████████| 9000/9000 [02:08<00:00, 69.82img/s, loss (batch)=1.19]\n",
            "INFO: Checkpoint 8 saved !\n",
            "Epoch 9/10: 100%|██████████| 9000/9000 [02:09<00:00, 69.64img/s, loss (batch)=1.12]\n",
            "INFO: Checkpoint 9 saved !\n",
            "Epoch 10/10: 100%|██████████| 9000/9000 [02:08<00:00, 69.77img/s, loss (batch)=1.12]\n",
            "INFO: Checkpoint 10 saved !\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK4f4lLvOenE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e35dcce3-67e8-44ec-986c-02e916578ac1"
      },
      "source": [
        "!cp checkpoints/*.pth '/content/drive/My Drive/Untitled folder/'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: target '/content/drive/My Drive/Untitled folder/' is not a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8e20Hc_VdM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmLcPPYcG4Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf sample50/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSX98Ieahewi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "from unet import UNet\n",
        "from utils.data_vis import plot_img_and_mask\n",
        "from utils.dataset import BasicDataset\n",
        "\n",
        "\n",
        "def predict_img2(net,\n",
        "                full_img,\n",
        "                device,\n",
        "                scale_factor=1,\n",
        "                out_threshold=0.5):\n",
        "    net.eval()\n",
        "\n",
        "    img = torch.from_numpy(BasicDataset.preprocess(full_img, scale_factor))\n",
        "\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(device=device, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        depth, mask = net(img) #depth, mask\n",
        "\n",
        "        if net.n_classes > 1:\n",
        "            probs1 = F.softmax(depth, dim=1)\n",
        "        else:\n",
        "            probs1 = torch.sigmoid(depth)\n",
        "            ############2\n",
        "        if net.n_classes > 1:\n",
        "            probs2 = F.softmax(mask, dim=1)\n",
        "        else:\n",
        "            probs2 = torch.sigmoid(mask)\n",
        "\n",
        "        probs1 = probs1.squeeze(0)\n",
        "\n",
        "        probs2 = probs2.squeeze(0)\n",
        "\n",
        "        tf = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize(full_img.size[1]),\n",
        "                transforms.ToTensor()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        probs1 = tf(probs1.cpu())\n",
        "        probs2 = tf(probs2.cpu())\n",
        "        full_depth = probs1.squeeze().cpu().numpy()\n",
        "        full_mask = probs2.squeeze().cpu().numpy()\n",
        "    full_depth = full_depth - np.min(full_depth)\n",
        "    full_depth = full_depth / np.max(full_depth)\n",
        "    return full_depth , full_mask > out_threshold\n",
        "\n",
        "\n",
        "def get_output_filenames(args):\n",
        "    in_files = args.input\n",
        "    out_files = []\n",
        "\n",
        "    if not args.output:\n",
        "        for f in in_files:\n",
        "            pathsplit = os.path.splitext(f)\n",
        "            out_files.append(\"{}_OUT{}\".format(pathsplit[0], pathsplit[1]))\n",
        "    elif len(in_files) != len(args.output):\n",
        "        logging.error(\"Input files and output files are not of the same length\")\n",
        "        raise SystemExit()\n",
        "    else:\n",
        "        out_files = args.output\n",
        "\n",
        "    return out_files\n",
        "\n",
        "\n",
        "def mask_to_image(mask):\n",
        "    return Image.fromarray((mask * 255).astype(np.uint8))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYDQzdmw7GwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir sample50\n",
        "!mkdir sample50/out\n",
        "!mkdir sample50/ind\n",
        "!mkdir sample50/act\n",
        "from predict import *\n",
        "from PIL import Image\n",
        "sdir = 'sample50/out/'\n",
        "actdir ='sample50/act/'\n",
        "indir ='sample50/ind/'\n",
        "for i,idx in enumerate(os.listdir('data/fgbg/')):\n",
        "  if i==10:\n",
        "    break;\n",
        "  img = Image.open('data/fgbg/'+idx)\n",
        "  img.save(indir+idx)\n",
        "  act = Image.open('data/depth/'+idx)\n",
        "  act.save(actdir+idx)\n",
        "  depth, mask = predict_img2(net=net, full_img=img, scale_factor=1.0, out_threshold=0.1, device=device)\n",
        "  result1 = mask_to_image(mask)\n",
        "  result2 = mask_to_image(depth)\n",
        "  result1.save(sdir+idx)\n",
        "  result2.save(sdir+'depth'+idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9nQUfwVVOS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir sample50/out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al-BSZjzC03W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from PIL import Image \n",
        "from predict import predict_img\n",
        "from matplotlib import cm\n",
        "import matplotlib\n",
        "net = UNet(3, 1).cuda()\n",
        "dire = 'sample50/fgbg/'\n",
        "sdir = 'sample50/out/'\n",
        "sdir = ''\n",
        "lst_msk = []\n",
        "net.load_state_dict(torch.load('/content/drive/My Drive/models/CP_epoch1.pth'))\n",
        "for i,dx in enumerate(listdir(dire)):\n",
        "  img = Image.open(dire+dx)\n",
        "  mask = predict_img(net, img, device)\n",
        "  matplotlib.image.imsave(sdir+dx, mask)\n",
        "  #im.save(sdir+dx)\n",
        "  lst_msk.append(mask)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgwkHi5lKaaP",
        "colab_type": "code",
        "outputId": "7e150dcd-3bd9-40c9-a616-227f1e9312a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(lst_msk)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZBuJqw9Dhfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "!mkdir sample10k\n",
        "!mkdir sample10k/fgbg\n",
        "!mkdir sample10k/depth\n",
        "!mkdir sample10k/mask\n",
        "!mkdir sample50\n",
        "!mkdir sample50/fgbg\n",
        "!mkdir sample50/depth\n",
        "!mkdir sample50/mask\n",
        "rootsrc = 'data/'\n",
        "import os\n",
        "for i,idx in enumerate(os.listdir(rootsrc+'fgbg/')):\n",
        "  if( i == 10000):\n",
        "    break\n",
        "  shutil.copy(rootsrc + 'fgbg/' + idx, 'sample10k/fgbg/') \n",
        "  shutil.copy(rootsrc + 'fgbgmask/' + idx, 'sample10k/mask/') \n",
        "  shutil.copy(rootsrc + 'Depthmap/' + idx, 'sample10k/depth/') \n",
        "  if (i<50):\n",
        "    shutil.copy(rootsrc + 'fgbg/' + idx, 'sample50/fgbg/') \n",
        "    shutil.copy(rootsrc + 'fgbgmask/' + idx, 'sample50/mask/') \n",
        "    shutil.copy(rootsrc + 'Depthmap/' + idx, 'sample50/depth/') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEhJzMC9NJI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r sample50 '/content/drive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOjX-T1fNsAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile \n",
        "import os \n",
        "  \n",
        "def get_all_file_paths(directory): \n",
        "  \n",
        "    # initializing empty file paths list \n",
        "    file_paths = [] \n",
        "  \n",
        "    # crawling through directory and subdirectories \n",
        "    for root, directories, files in os.walk(directory): \n",
        "        for filename in files: \n",
        "            # join the two strings in order to form the full filepath. \n",
        "            filepath = os.path.join(root, filename) \n",
        "            file_paths.append(filepath) \n",
        "  \n",
        "    # returning all file paths \n",
        "    return file_paths         \n",
        "  \n",
        "def main(): \n",
        "    # path to folder which needs to be zipped \n",
        "    directory = 'sample10k/'\n",
        "  \n",
        "    # calling function to get all file paths in the directory \n",
        "    file_paths = get_all_file_paths(directory) \n",
        "  \n",
        "    # printing the list of all files to be zipped \n",
        "    print('Following files will be zipped:') \n",
        "    for file_name in file_paths: \n",
        "        print(file_name) \n",
        "  \n",
        "    # writing files to a zipfile \n",
        "    with ZipFile('sample10.zip','w') as zip: \n",
        "        # writing each file one by one \n",
        "        for file in file_paths: \n",
        "            zip.write(file) \n",
        "  \n",
        "    print('All files zipped successfully!')  \n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3oxkK1hPHVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp sample10.zip '/content/drive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu-4dDghfhQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset\n",
        "from os.path import splitext\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import logging\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class BasicDataset(Dataset):\n",
        "    def __init__(self, imgs_dir, masks_dir, depth_dir, scale=1):\n",
        "        self.imgs_dir = imgs_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.depth_dir = depth_dir\n",
        "        self.scale = scale\n",
        "        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n",
        "\n",
        "        self.ids = listdir(self.imgs_dir)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    @classmethod\n",
        "    def preprocess(cls, pil_img, scale):\n",
        "        w, h = pil_img.size\n",
        "        newW, newH = int(scale * w), int(scale * h)\n",
        "        assert newW > 0 and newH > 0, 'Scale is too small'\n",
        "        pil_img = pil_img.resize((newW, newH))\n",
        "\n",
        "        img_nd = np.array(pil_img)\n",
        "\n",
        "        if len(img_nd.shape) == 2:\n",
        "            img_nd = np.expand_dims(img_nd, axis=2)\n",
        "\n",
        "        # HWC to CHW\n",
        "        img_trans = img_nd.transpose((2, 0, 1))\n",
        "        if img_trans.max() > 1:\n",
        "            img_trans = img_trans / 255\n",
        "\n",
        "        return img_trans\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        idx = self.ids[i]\n",
        "        mask_file = self.masks_dir + idx #glob(self.masks_dir + idx + '*')\n",
        "        img_file = self.imgs_dir + idx #glob(self.imgs_dir + idx + '*')\n",
        "        depth_file = self.depth_dir + idx\n",
        "\n",
        "        # assert len(mask_file) == 1, \\\n",
        "        #     f'Either no mask or multiple masks found for the ID {idx}: {mask_file}'\n",
        "        # assert len(img_file) == 1, \\\n",
        "        #     f'Either no image or multiple images found for the ID {idx}: {img_file}'\n",
        "        mask = Image.open(mask_file)\n",
        "        img = Image.open(img_file)\n",
        "        depth = Image.open(depth_file)\n",
        "\n",
        "        assert img.size == mask.size, \\\n",
        "            f'Image and mask {idx} should be the same size, but are {img.size} and {mask.size}'\n",
        "\n",
        "        img = self.preprocess(img, self.scale)\n",
        "        mask = self.preprocess(mask, self.scale)\n",
        "        depth =self.preprocess(depth, self.scale)\n",
        "\n",
        "        return {'image': torch.from_numpy(img), 'mask': torch.from_numpy(mask), 'depth': torch.from_numpy(depth)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWfVegUQg4O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
        "#unet_model\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from .unet_parts import *\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 32)\n",
        "        self.down1 = Down(32, 64)\n",
        "        self.down2 = Down(64, 128)\n",
        "        self.down3 = Down(128, 256)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(256, 512 // factor)\n",
        "        self.up1 = Up(512, 256 // factor, bilinear)\n",
        "        self.up2 = Up(256, 128 // factor, bilinear)\n",
        "        self.up3 = Up(128, 64 // factor, bilinear)\n",
        "        self.up4 = Up(64, 32, bilinear)\n",
        "        self.outc = OutConv(32, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        rt_depth = self.outc(x)\n",
        "\n",
        "        y1 = self.inc(y) #------------\n",
        "        y2 = self.down1(y1) #------------\n",
        "        y3 = self.down2(y2) #------------ \n",
        "        y4 = self.down3(y3) #------------\n",
        "        y5 = self.down4(y4) #------------\n",
        "        y = self.up1(y5, y4) #------------\n",
        "        y = self.up2(y, y3) #------------\n",
        "        y = self.up3(y, y2) #------------\n",
        "        y = self.up4(y, y1) #------------\n",
        "        rt_mask = self.outc(y) #------------\n",
        "        return rt_depth, rt_mask #\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jge46LFCzjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "from unet import UNet\n",
        "from utils.data_vis import plot_img_and_mask\n",
        "from utils.dataset import BasicDataset\n",
        "\n",
        "\n",
        "def predict_img(net,\n",
        "                full_img,\n",
        "                device,\n",
        "                scale_factor=1,\n",
        "                out_threshold=0.5):\n",
        "    net.eval()\n",
        "\n",
        "    img = torch.from_numpy(BasicDataset.preprocess(full_img, scale_factor))\n",
        "\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(device=device, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        depth, mask = net(img) #depth, mask\n",
        "\n",
        "        if net.n_classes > 1:\n",
        "            probs1 = F.softmax(depth, dim=1)\n",
        "        else:\n",
        "            probs1 = torch.sigmoid(depth)\n",
        "            ############2\n",
        "        if net.n_classes > 1:\n",
        "            probs2 = F.softmax(mask, dim=1)\n",
        "        else:\n",
        "            probs2 = torch.sigmoid(mask)\n",
        "\n",
        "        probs1 = probs1.squeeze(0)\n",
        "\n",
        "        probs2 = probs2.squeeze(0)\n",
        "\n",
        "        tf = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize(full_img.size[1]),\n",
        "                transforms.ToTensor()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        probs1 = tf(probs1.cpu())\n",
        "        probs2 = tf(probs2.cpu())\n",
        "        full_depth = probs1.squeeze().cpu().numpy()\n",
        "        full_mask = probs2.squeeze().cpu().numpy()\n",
        "    full_depth = full_depth - np.min(full_depth)\n",
        "    full_depth = full_depth / np.max(full_depth)\n",
        "    return full_depth , full_mask# > out_threshold\n",
        "\n",
        "\n",
        "def get_output_filenames(args):\n",
        "    in_files = args.input\n",
        "    out_files = []\n",
        "\n",
        "    if not args.output:\n",
        "        for f in in_files:\n",
        "            pathsplit = os.path.splitext(f)\n",
        "            out_files.append(\"{}_OUT{}\".format(pathsplit[0], pathsplit[1]))\n",
        "    elif len(in_files) != len(args.output):\n",
        "        logging.error(\"Input files and output files are not of the same length\")\n",
        "        raise SystemExit()\n",
        "    else:\n",
        "        out_files = args.output\n",
        "\n",
        "    return out_files\n",
        "\n",
        "\n",
        "def mask_to_image(mask):\n",
        "    return Image.fromarray((mask * 255).astype(np.uint8))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}