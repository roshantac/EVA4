{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshantac/EVA4/blob/master/Assignment15/B/finlworkinTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qquZYzsvaLyz",
        "colab_type": "code",
        "outputId": "9ecef151-57ce-4cc6-f7fb-c491a5c183f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wed May 20 02:04:53 2020       ',\n",
              " '+-----------------------------------------------------------------------------+',\n",
              " '| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |',\n",
              " '|-------------------------------+----------------------+----------------------+',\n",
              " '| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |',\n",
              " '| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |',\n",
              " '|===============================+======================+======================|',\n",
              " '|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |',\n",
              " '| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |',\n",
              " '+-------------------------------+----------------------+----------------------+',\n",
              " '                                                                               ',\n",
              " '+-----------------------------------------------------------------------------+',\n",
              " '| Processes:                                                       GPU Memory |',\n",
              " '|  GPU       PID   Type   Process name                             Usage      |',\n",
              " '|=============================================================================|',\n",
              " '|  No running processes found                                                 |',\n",
              " '+-----------------------------------------------------------------------------+']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz41fo52a-Np",
        "colab_type": "code",
        "outputId": "4c0284d5-69cd-4b75-9cc8-cd1036bfff66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/roshantac/Unet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Unet'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 51 (delta 20), reused 30 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXRBXDB8u5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Unet/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONDvNBUxbxh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "99e7d8bb-ab10-4b55-d5d1-632d942ae5ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwh6CNzBbIr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Dataset\n",
        "!cp '/content/drive/My Drive/Rohit dataset/Dataset.zip' Dataset\n",
        "#!cp '/content/drive/My Drive/sample10.zip' temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TChDfT0a9LiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "destDataDir = '/content/temp/'\n",
        "path_to_zip_file = '/content/temp/Dataset.zip'\n",
        "import zipfile\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destDataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDQg9tG_c4Vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# destDataDir = '/content/temp/'\n",
        "# path_to_zip_file = '/content/temp/sample10.zip'\n",
        "# import zipfile\n",
        "# with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(destDataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyi6tClyd8LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mv '/content/temp/sample10k/depth' '/content/Unet/data/'\n",
        "# !mv '/content/temp/sample10k/fgbg' '/content/Unet/data/'\n",
        "# !mv '/content/temp/sample10k/mask' '/content/Unet/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e4dVW1mfJJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urmqrDaqfzDE",
        "colab_type": "code",
        "outputId": "a5c1e5fb-9d4b-47bd-9eee-b7298364b1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd Unet/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Unet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dq22dgZ-777",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "from eval import eval_net\n",
        "from unet import UNet\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from utils.dataset import BasicDataset\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx-6s2yD-2Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = '/content/'\n",
        "dir_checkpoint = 'checkpoints/'\n",
        "\n",
        "def train_net(net, device, epochs = 10, batch_size = 1, lr = 0.001, val_percent  =0.2, save_cp = True, img_scale = 0.5):\n",
        "    dataset = BasicDataset(root)\n",
        "    n_val = int(len(dataset) * val_percent)\n",
        "    n_train = len(dataset) - n_val\n",
        "    train, val = random_split(dataset, [n_train, n_val])\n",
        "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
        "\n",
        "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{img_scale}')\n",
        "    global_step = 0\n",
        "\n",
        "    logging.info(f'''Starting training:\n",
        "        Epochs:          {epochs}\n",
        "        Batch size:      {batch_size}\n",
        "        Learning rate:   {lr}\n",
        "        Training size:   {n_train}\n",
        "        Validation size: {n_val}\n",
        "        Checkpoints:     {save_cp}\n",
        "        Device:          {device.type}\n",
        "        Images scaling:  {img_scale}\n",
        "    ''')\n",
        "\n",
        "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)\n",
        "    if net.n_classes > 1:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "\n",
        "        epoch_loss = 0\n",
        "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
        "            for batch in train_loader:\n",
        "                batch['bg'] = batch['bg'].to(device, dtype = torch.float32)\n",
        "                batch['fgbg'] = batch['fgbg'].to(device, dtype = torch.float32)\n",
        "                batch['mask'] = batch['mask'].to(device, dtype = torch.float32)\n",
        "                batch['depth'] = batch['depth'].to(device, dtype = torch.float32) \n",
        "                # assert imgs.batch[1] == net.n_channels, \\\n",
        "                #     f'Network has been defined with {net.n_channels} input channels, ' \\\n",
        "                #     f'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
        "                #     'the images are loaded correctly.'\n",
        "                # bg = bg.to(device=device, dtype = torch.float32)\n",
        "                # imgs = imgs.to(device=device, dtype=torch.float32)\n",
        "                # mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
        "                # true_masks = true_masks.to(device=device, dtype=mask_type)\n",
        "                # true_depth = true_depth.to(device=device, dtype=torch.float32) #------------------------add----------------\n",
        "\n",
        "                depth_pred, masks_pred = net(batch)\n",
        "                loss1 = criterion(masks_pred, batch['mask'])\n",
        "                loss2 = criterion(depth_pred, batch['depth']) #------------------------add----------------\n",
        "                loss = loss1 + loss2 #------------------------add----------------\n",
        "                epoch_loss += loss.item()\n",
        "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
        "\n",
        "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
        "                optimizer.step()\n",
        "\n",
        "                pbar.update(batch['fgbg'].shape[0])\n",
        "                global_step += 1\n",
        "                # if global_step % (len(dataset) // (10 * batch_size)) == 0:\n",
        "                #     for tag, value in net.named_parameters():\n",
        "                #         tag = tag.replace('.', '/')\n",
        "                #         writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
        "                #         writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
        "                #     val_score = eval_net(net, val_loader, device)\n",
        "                #     scheduler.step(val_score)\n",
        "                #     writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
        "\n",
        "                #     if net.n_classes > 1:\n",
        "                #         logging.info('Validation cross entropy: {}'.format(val_score))\n",
        "                #         writer.add_scalar('Loss/test', val_score, global_step)\n",
        "                #     else:\n",
        "                #         logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
        "                #         writer.add_scalar('Dice/test', val_score, global_step)\n",
        "\n",
        "                #     writer.add_images('images', imgs, global_step)\n",
        "                #     if net.n_classes == 1:\n",
        "                #         writer.add_images('masks/true', true_masks, global_step)\n",
        "                #         writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
        "\n",
        "        if save_cp:\n",
        "            try:\n",
        "                os.mkdir(dir_checkpoint)\n",
        "                logging.info('Created checkpoint directory')\n",
        "            except OSError:\n",
        "                pass\n",
        "            torch.save(net.state_dict(),\n",
        "                       dir_checkpoint + f'CP_epoch{epoch + 1}.pth')\n",
        "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
        "\n",
        "    writer.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x49_wteDJB1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = next(iter(train_dl))\n",
        "[(k, v.shape) for k, v in sample.items()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3unl_YZQGz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29d027f4-2e9b-447b-8032-01027395da66"
      },
      "source": [
        "net = UNet(n_channels=6, n_classes=1, bilinear=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device=device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (inc): DoubleConv(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (down1): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down4): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up1): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up4): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (outc): OutConv(\n",
              "    (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SeS-xSeInvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show(tensors, figsize= (10,10), *args, **kwargs):\n",
        "  try:\n",
        "    tensors = tensors.detach().cpu()\n",
        "  except:\n",
        "    pass\n",
        "  grid_tensor = torchvision.utils.make_grid(tensors, *args, **kwargs)  \n",
        "  grid_image  = grid_tensor.permute(1, 2, 0)\n",
        "  plt.figure(figsize = figsize)\n",
        "  plt.imshow(grid_image)\n",
        "  plt.xticks([])  \n",
        "  plt.yticks([])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1Ckms7tIqhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_pred(tensors, *args, **kwargs):\n",
        "  tensors = (tensors * std[None, : , None, None]) + mean[None, :, None, None]\n",
        "  show(tensors, *args, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJwPEUMPIuBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show(imgs, nrow=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sqw9aCdQHVa",
        "colab_type": "code",
        "outputId": "66d36f66-c213-4851-85f7-842f61398372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(net, (3,224,224))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4c3a825044fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Unet/unet/unet_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fgbg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mdat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdat1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOogjh1fQtf",
        "colab_type": "code",
        "outputId": "ae25bfa0-4b9f-45a3-86c6-584adb96e4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
        "\n",
        "logging.info(f'Using device {device}')\n",
        "\n",
        "# Change here to adapt to your data\n",
        "# n_channels=3 for RGB images\n",
        "# n_classes is the number of probabilities you want to get per pixel\n",
        "#   - For 1 class and background, use n_classes=1\n",
        "#   - For 2 classes, use n_classes=1\n",
        "#   - For N > 2 classes, use n_classes=N\n",
        "\n",
        "logging.info(f'Network:\\n'\n",
        "              f'\\t{net.n_channels} input channels\\n'\n",
        "              f'\\t{net.n_classes} output channels (classes)\\n'\n",
        "              f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
        "\n",
        "\n",
        "# faster convolutions, but more \n",
        "torch.backends.cudnn.benchmark=True\n",
        "# Train\n",
        "train_net(net=net,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          lr=0.001,\n",
        "          device=device,\n",
        "          img_scale=1.0,\n",
        "          val_percent= 30.0/ 100)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Using device cuda\n",
            "INFO: Network:\n",
            "\t6 input channels\n",
            "\t1 output channels (classes)\n",
            "\tBilinear upscaling\n",
            "INFO: Starting training:\n",
            "        Epochs:          10\n",
            "        Batch size:      32\n",
            "        Learning rate:   0.001\n",
            "        Training size:   7000\n",
            "        Validation size: 3000\n",
            "        Checkpoints:     True\n",
            "        Device:          cuda\n",
            "        Images scaling:  1.0\n",
            "    \n",
            "Epoch 1/10: 100%|██████████| 7000/7000 [01:59<00:00, 58.54img/s, loss (batch)=0.987]\n",
            "INFO: Created checkpoint directory\n",
            "INFO: Checkpoint 1 saved !\n",
            "Epoch 2/10: 100%|██████████| 7000/7000 [01:55<00:00, 60.57img/s, loss (batch)=0.989]\n",
            "INFO: Checkpoint 2 saved !\n",
            "Epoch 3/10: 100%|██████████| 7000/7000 [01:55<00:00, 60.58img/s, loss (batch)=1.01]\n",
            "INFO: Checkpoint 3 saved !\n",
            "Epoch 4/10: 100%|██████████| 7000/7000 [01:55<00:00, 60.58img/s, loss (batch)=0.997]\n",
            "INFO: Checkpoint 4 saved !\n",
            "Epoch 5/10: 100%|██████████| 7000/7000 [01:55<00:00, 60.55img/s, loss (batch)=1.01]\n",
            "INFO: Checkpoint 5 saved !\n",
            "Epoch 6/10: 100%|██████████| 7000/7000 [01:54<00:00, 60.92img/s, loss (batch)=1.02]\n",
            "INFO: Checkpoint 6 saved !\n",
            "Epoch 7/10: 100%|██████████| 7000/7000 [01:55<00:00, 60.49img/s, loss (batch)=0.99]\n",
            "INFO: Checkpoint 7 saved !\n",
            "Epoch 8/10: 100%|██████████| 7000/7000 [01:55<00:00, 60.80img/s, loss (batch)=0.988]\n",
            "INFO: Checkpoint 8 saved !\n",
            "Epoch 9/10: 100%|██████████| 7000/7000 [01:55<00:00, 60.57img/s, loss (batch)=1.01]\n",
            "INFO: Checkpoint 9 saved !\n",
            "Epoch 10/10: 100%|██████████| 7000/7000 [01:55<00:00, 60.77img/s, loss (batch)=0.995]\n",
            "INFO: Checkpoint 10 saved !\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK4f4lLvOenE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e35dcce3-67e8-44ec-986c-02e916578ac1"
      },
      "source": [
        "!cp checkpoints/*.pth '/content/drive/My Drive/Untitled folder/'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: target '/content/drive/My Drive/Untitled folder/' is not a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFpfDIogw96x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32fb8763-535d-4de3-b9c3-9bb9e59e5368"
      },
      "source": [
        "c =\"Dataset/bg/bg32.jpg\"\n",
        "print(c)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset/bg/bg32.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8e20Hc_VdM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmLcPPYcG4Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf sample50/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSX98Ieahewi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "from unet import UNet\n",
        "from utils.data_vis import plot_img_and_mask\n",
        "from utils.dataset import BasicDataset\n",
        "\n",
        "\n",
        "def predict_img2(net,\n",
        "                full_img,\n",
        "                device,\n",
        "                scale_factor=1,\n",
        "                out_threshold=0.5):\n",
        "    net.eval()\n",
        "\n",
        "    img = torch.from_numpy(BasicDataset.preprocess(full_img, scale_factor))\n",
        "\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(device=device, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        depth, mask = net(img) #depth, mask\n",
        "\n",
        "        if net.n_classes > 1:\n",
        "            probs1 = F.softmax(depth, dim=1)\n",
        "        else:\n",
        "            probs1 = torch.sigmoid(depth)\n",
        "            ############2\n",
        "        if net.n_classes > 1:\n",
        "            probs2 = F.softmax(mask, dim=1)\n",
        "        else:\n",
        "            probs2 = torch.sigmoid(mask)\n",
        "\n",
        "        probs1 = probs1.squeeze(0)\n",
        "\n",
        "        probs2 = probs2.squeeze(0)\n",
        "\n",
        "        tf = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize(full_img.size[1]),\n",
        "                transforms.ToTensor()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        probs1 = tf(probs1.cpu())\n",
        "        probs2 = tf(probs2.cpu())\n",
        "        full_depth = probs1.squeeze().cpu().numpy()\n",
        "        full_mask = probs2.squeeze().cpu().numpy()\n",
        "    full_depth = full_depth - np.min(full_depth)\n",
        "    full_depth = full_depth / np.max(full_depth)\n",
        "    return full_depth , full_mask #> out_threshold\n",
        "\n",
        "\n",
        "def get_output_filenames(args):\n",
        "    in_files = args.input\n",
        "    out_files = []\n",
        "\n",
        "    if not args.output:\n",
        "        for f in in_files:\n",
        "            pathsplit = os.path.splitext(f)\n",
        "            out_files.append(\"{}_OUT{}\".format(pathsplit[0], pathsplit[1]))\n",
        "    elif len(in_files) != len(args.output):\n",
        "        logging.error(\"Input files and output files are not of the same length\")\n",
        "        raise SystemExit()\n",
        "    else:\n",
        "        out_files = args.output\n",
        "\n",
        "    return out_files\n",
        "\n",
        "\n",
        "def mask_to_image(mask):\n",
        "    return Image.fromarray((mask * 255).astype(np.uint8))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYDQzdmw7GwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir sample50\n",
        "!mkdir sample50/out\n",
        "!mkdir sample50/ind\n",
        "!mkdir sample50/act\n",
        "from predict import *\n",
        "from PIL import Image\n",
        "sdir = 'sample50/out/'\n",
        "actdir ='sample50/act/'\n",
        "indir ='sample50/ind/'\n",
        "for i,idx in enumerate(os.listdir('data/fgbg/')):\n",
        "  if i==10:\n",
        "    break;\n",
        "  img = Image.open('data/fgbg/'+idx)\n",
        "  img.save(indir+idx)\n",
        "  act = Image.open('data/depth/'+idx)\n",
        "  act.save(actdir+idx)\n",
        "  depth, mask = predict_img2(net=net, full_img=img, scale_factor=1.0, out_threshold=0.1, device=device)\n",
        "  result1 = mask_to_image(mask)\n",
        "  result2 = mask_to_image(depth)\n",
        "  result1.save(sdir+idx)\n",
        "  result2.save(sdir+'depth'+idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9nQUfwVVOS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir sample50/out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEhJzMC9NJI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r sample50 '/content/drive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu-4dDghfhQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset\n",
        "from os.path import splitext\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import logging\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class BasicDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        data_file = open(root+'Dataset/'+'label_data.csv')\n",
        "        self.data = data_file.readlines()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    @classmethod\n",
        "    def preprocess(cls, pil_img):\n",
        "\n",
        "        img_nd = np.array(pil_img)\n",
        "\n",
        "        if len(img_nd.shape) == 2:\n",
        "            img_nd = np.expand_dims(img_nd, axis=2)\n",
        "\n",
        "        # HWC to CHW\n",
        "        img_trans = img_nd.transpose((2, 0, 1))\n",
        "        if img_trans.max() > 1:\n",
        "            img_trans = img_trans / 255\n",
        "        return img_trans\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        idx = self.data[i].split(';')\n",
        "        bg = Image.open(self.root + idx[0].replace('\"',''))\n",
        "        fgbg = Image.open(self.root + idx[1].replace('\"',''))\n",
        "        mask = Image.open(self.root + idx[2].replace('\"',''))\n",
        "        depth = Image.open(self.root + idx[3].replace('\"','').replace('\\n',''))\n",
        "        bg = self.preprocess(bg)\n",
        "        fgbg = self.preprocess(fgbg)\n",
        "        mask = self.preprocess(mask)\n",
        "        depth =self.preprocess(depth)\n",
        "        return {'bg' : torch.from_numpy(bg), 'fgbg': torch.from_numpy(fgbg), 'mask': torch.from_numpy(mask), 'depth': torch.from_numpy(depth)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWfVegUQg4O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
        "#unet_model\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from .unet_parts import *\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 32)\n",
        "        self.down1 = Down(32, 64)\n",
        "        self.down2 = Down(64, 128)\n",
        "        self.down3 = Down(128, 256)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(256, 512 // factor)\n",
        "        self.up1 = Up(512, 256 // factor, bilinear)\n",
        "        self.up2 = Up(256, 128 // factor, bilinear)\n",
        "        self.up3 = Up(128, 64 // factor, bilinear)\n",
        "        self.up4 = Up(64, 32, bilinear)\n",
        "        self.outc = OutConv(32, n_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        dat1 = data['fgbg']\n",
        "        dat2 = data['bg']\n",
        "        x = torch.cat([dat1,dat2], dim = 1)\n",
        "        y = x\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        rt_depth = self.outc(x)\n",
        "\n",
        "        y1 = self.inc(y) #------------\n",
        "        y2 = self.down1(y1) #------------\n",
        "        y3 = self.down2(y2) #------------ \n",
        "        y4 = self.down3(y3) #------------\n",
        "        y5 = self.down4(y4) #------------\n",
        "        y = self.up1(y5, y4) #------------\n",
        "        y = self.up2(y, y3) #------------\n",
        "        y = self.up3(y, y2) #------------\n",
        "        y = self.up4(y, y1) #------------\n",
        "        rt_mask = self.outc(y) #------------\n",
        "        return rt_depth, rt_mask #\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jge46LFCzjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "from unet import UNet\n",
        "from utils.data_vis import plot_img_and_mask\n",
        "from utils.dataset import BasicDataset\n",
        "\n",
        "\n",
        "def predict_img(net,\n",
        "                full_img,\n",
        "                device,\n",
        "                scale_factor=1,\n",
        "                out_threshold=0.5):\n",
        "    net.eval()\n",
        "\n",
        "    img = torch.from_numpy(BasicDataset.preprocess(full_img))\n",
        "\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(device=device, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        depth, mask = net(img) #depth, mask\n",
        "\n",
        "        if net.n_classes > 1:\n",
        "            probs1 = F.softmax(depth, dim=1)\n",
        "        else:\n",
        "            probs1 = torch.sigmoid(depth)\n",
        "            ############2\n",
        "        if net.n_classes > 1:\n",
        "            probs2 = F.softmax(mask, dim=1)\n",
        "        else:\n",
        "            probs2 = torch.sigmoid(mask)\n",
        "\n",
        "        probs1 = probs1.squeeze(0)\n",
        "\n",
        "        probs2 = probs2.squeeze(0)\n",
        "\n",
        "        tf = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize(full_img.size[1]),\n",
        "                transforms.ToTensor()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        probs1 = tf(probs1.cpu())\n",
        "        probs2 = tf(probs2.cpu())\n",
        "        full_depth = probs1.squeeze().cpu().numpy()\n",
        "        full_mask = probs2.squeeze().cpu().numpy()\n",
        "    full_depth = full_depth - np.min(full_depth)\n",
        "    full_depth = full_depth / np.max(full_depth)\n",
        "    return full_depth , full_mask# > out_threshold\n",
        "\n",
        "\n",
        "def get_output_filenames(args):\n",
        "    in_files = args.input\n",
        "    out_files = []\n",
        "\n",
        "    if not args.output:\n",
        "        for f in in_files:\n",
        "            pathsplit = os.path.splitext(f)\n",
        "            out_files.append(\"{}_OUT{}\".format(pathsplit[0], pathsplit[1]))\n",
        "    elif len(in_files) != len(args.output):\n",
        "        logging.error(\"Input files and output files are not of the same length\")\n",
        "        raise SystemExit()\n",
        "    else:\n",
        "        out_files = args.output\n",
        "\n",
        "    return out_files\n",
        "\n",
        "\n",
        "def mask_to_image(mask):\n",
        "    return Image.fromarray((mask * 255).astype(np.uint8))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}