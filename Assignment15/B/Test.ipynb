{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "mount_file_id": "1xibXLW68uZx_VXR0Yni0TEH2xb_omg1A",
      "authorship_tag": "ABX9TyNJBWfujaOn+ckUEbDLxuAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshantac/EVA4/blob/master/Assignment15/B/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgGaT-xzo8J-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHhJImoQpRhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from torch.tils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from torchvission.transforms import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvission\n",
        "from torch import nn\n",
        "import torch\n",
        "from kornia.losses import SSIM\n",
        "\n",
        "root = \"/content/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3hlFkUKpbzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataSet(Dataset):\n",
        "    def __init__(self, self.root):\n",
        "        self.transfrm_fgbg = transforms.Compose([transforms.Resize((200,200)),\n",
        "        transforms.ToTensor(),transforms.Normalize(mean,std),])\n",
        "        \n",
        "        self.transfrm_mask  = transforms.Compose([transforms.Resize((200,200)),transforms.ToTensor(),])\n",
        "        \n",
        "        self.transfrm_mask = transforms.Compose([transforms.Resize((200,200)),transforms.ToTensor(),])\n",
        "        #put transforms here\n",
        "        self.fgbg = \n",
        "    def __len__(self):\n",
        "        return len(self.fgbg)\n",
        "    def __getitem__(self,index):\n",
        "        img = self.fgbg[index]\n",
        "        imgmsk = 'mask' + img[3:] \n",
        "        fgbg_img = self.transfrm_fgbg(Image.open(self.root + '/fgbg/'+img))\n",
        "        msk_img  = self.transfrm_mask(Image.open(self.root + '/fgbgmask/'+imgmsk))\n",
        "        depth_img= self.transfrm_depth(Image.open(self.root + '/Depthmap/'+img))\n",
        "        return {'image':fgbg_img, 'mask':imgmsk,'depth':depth_img}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6YS3020pdMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def FetchImage(root,index):\n",
        "    img = self.fgbg[index]\n",
        "    imgmsk = 'mask' + img[3:] \n",
        "    fgbg = Image.open(root + '/fgbg/'+img)\n",
        "    msk = Image.open(root + '/fgbgmask/'+imgmsk)\n",
        "    depth = Image.open(root + '/Depthmap/'+img)\n",
        "    return {'image':fgbg, 'mask':msk,'depth':depth}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghd2oalhpgnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvGen(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(ConvGen,self).__init__()\n",
        "\n",
        "      self.convblock1 = nn.Sequential(\n",
        "          nn.Conv2d(3, 32, 3, stride =1, padding =1, bias = False),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLu()\n",
        "          )\n",
        "      self.convblock2 = nn.Sequential(\n",
        "          nn.Conv2d(32,64,3,stride=1, padding=1, bias=False),\n",
        "          nn.Conv2d(64,128,1,stride,padding=0,bias=False),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.ReLu()\n",
        "          )\n",
        "      self.convblock3 = nn.Sequential(\n",
        "          nn.Conv2d(128,256,3,stride=1,padding=1,bias=False),\n",
        "          nn.BatchNorm2d(256),\n",
        "          nn.ReLu()\n",
        "          )\n",
        "      self.convblock4 = nn.Sequential(\n",
        "          nn.Conv2d(256,3,3,stride=1,padding=1,bias= False),\n",
        "          )\n",
        "  def forward(self,sample):\n",
        "      f = sample[\"image\"] \n",
        "      f = self.convblock2(self.convblock1(f))\n",
        "      f = self.convblock4(self.convblock3(f))\n",
        "      return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qkHbwk8puVO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "517bd9a1-f8cb-427d-c71c-22efec82d45b"
      },
      "source": [
        "trainset = ImageDataSet(root)\n",
        "trainloader = DataLoader(trainset, batch_size = 16, shuffle =True, pin_memory=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0baa9a4bc9fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataSet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qliW8X6Ppx7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss() #SSIM( 3, reduction =\"mean\")\n",
        "model = ConvGen()\n",
        "#model.cuda()\n",
        "from torchsummary import summary\n",
        "summary(model, (3,200,200))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8qS9KdBp4iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = torch.optim.SGD(model.parameters(),lr= 0.01, momentum=0.9, weight_decay=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApeKZSZyp7JA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,criterion,device,trainloader,optimizer,epochs):\n",
        "    data[\"image\"] = data[\"image\"].to(device)\n",
        "    data[\"mask\"] = data[\"mask\"].to(device)\n",
        "    #data[\"depth\"] = data[\"depth\"].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss =criterion(output,data[\"mask\"])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if btach_idx %50 == 0:\n",
        "        print('Train Epoch: {}  [{}/{}  ({:.0f}%)]\\tLoss:{:.6f}'.format(\n",
        "            epochs,btach_idx*len(data),len(trainloader.dataset),\n",
        "            100.*btach_idx/len(trainloader),loss.item()))\n",
        "        print('Batch ID: ',btach_idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pCNdW6Tp9yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model,criterion, device,testloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.noo_grad():\n",
        "        for data in testloader:\n",
        "            data['image'] = data['image'].to(device)\n",
        "            data['mask'] = data['mask'].to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            test_loss += criterion(output,data['mask'],reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim =True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss/=len(testloader.dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcjICLh5qCqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "model = model.to(device)\n",
        "scheduler = StepLR(optim, step_size =1, gamma=0.01)\n",
        "for epoch in range(1, 10):\n",
        "    train(model, criterion, device, trainloader,optim, epoch)\n",
        "    scheduler.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}