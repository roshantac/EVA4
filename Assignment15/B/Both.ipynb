{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-mneloMAo8sypXz7iU22oAPHhOKp2et7",
      "authorship_tag": "ABX9TyMi1m5frFkcY7FX4FVewqgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshantac/EVA4/blob/master/Assignment15/B/Both.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qquZYzsvaLyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "5b4247ba-7cf5-4470-c0c8-66f82ef4e0e6"
      },
      "source": [
        "!!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sun May 17 19:39:44 2020       ',\n",
              " '+-----------------------------------------------------------------------------+',\n",
              " '| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |',\n",
              " '|-------------------------------+----------------------+----------------------+',\n",
              " '| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |',\n",
              " '| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |',\n",
              " '|===============================+======================+======================|',\n",
              " '|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |',\n",
              " '| N/A   30C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |',\n",
              " '+-------------------------------+----------------------+----------------------+',\n",
              " '                                                                               ',\n",
              " '+-----------------------------------------------------------------------------+',\n",
              " '| Processes:                                                       GPU Memory |',\n",
              " '|  GPU       PID   Type   Process name                             Usage      |',\n",
              " '|=============================================================================|',\n",
              " '|  No running processes found                                                 |',\n",
              " '+-----------------------------------------------------------------------------+']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz41fo52a-Np",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "01756c35-7afd-4610-a751-f6fd11203ba0"
      },
      "source": [
        "!git clone https://github.com/roshantac/Unet.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Unet'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 44 (delta 16), reused 31 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXRBXDB8u5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Unet/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONDvNBUxbxh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwh6CNzBbIr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir temp\n",
        "#!cp '/content/drive/My Drive/Eva_DataSet.zip' temp\n",
        "!cp '/content/drive/My Drive/sample10.zip' temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDQg9tG_c4Vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "destDataDir = '/content/temp/'\n",
        "path_to_zip_file = '/content/temp/sample10.zip'\n",
        "import zipfile\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destDataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyi6tClyd8LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv '/content/temp/sample10k/depth' '/content/Unet/data/'\n",
        "!mv '/content/temp/sample10k/fgbg' '/content/Unet/data/'\n",
        "!mv '/content/temp/sample10k/mask' '/content/Unet/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e4dVW1mfJJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urmqrDaqfzDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9b68d74-5ec8-4867-b291-6a0945a76190"
      },
      "source": [
        "%cd Unet/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Unet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dq22dgZ-777",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "from eval import eval_net\n",
        "from unet import UNet\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from utils.dataset import BasicDataset\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx-6s2yD-2Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_img = 'data/fgbg/'\n",
        "dir_mask = 'data/depth/'\n",
        "dir_checkpoint = 'checkpoints/'\n",
        "\n",
        "def train_net(net, device, epochs = 10, batch_size = 1, lr = 0.001, val_percent  =0.2, save_cp = True, img_scale = 0.5):\n",
        "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
        "    n_val = int(len(dataset) * val_percent)\n",
        "    n_train = len(dataset) - n_val\n",
        "    train, val = random_split(dataset, [n_train, n_val])\n",
        "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
        "\n",
        "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{img_scale}')\n",
        "    global_step = 0\n",
        "\n",
        "    logging.info(f'''Starting training:\n",
        "        Epochs:          {epochs}\n",
        "        Batch size:      {batch_size}\n",
        "        Learning rate:   {lr}\n",
        "        Training size:   {n_train}\n",
        "        Validation size: {n_val}\n",
        "        Checkpoints:     {save_cp}\n",
        "        Device:          {device.type}\n",
        "        Images scaling:  {img_scale}\n",
        "    ''')\n",
        "\n",
        "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)\n",
        "    if net.n_classes > 1:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "\n",
        "        epoch_loss = 0\n",
        "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
        "            for batch in train_loader:\n",
        "                imgs = batch['image']\n",
        "                true_masks = batch['mask']\n",
        "                true_depth = batch['depth'] #------------------------add----------------\n",
        "                assert imgs.shape[1] == net.n_channels, \\\n",
        "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
        "                    f'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
        "                    'the images are loaded correctly.'\n",
        "\n",
        "                imgs = imgs.to(device=device, dtype=torch.float32)\n",
        "                mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
        "                true_masks = true_masks.to(device=device, dtype=mask_type)\n",
        "                true_depth = true_depth.to(device=device, dtype=torch.float32) #------------------------add----------------\n",
        "\n",
        "                masks_pred = net(imgs)\n",
        "                loss1 = criterion(masks_pred, true_masks)\n",
        "                loss2 = criterion(depth_pred, true_depth) #------------------------add----------------\n",
        "                loss = loss1 + 2*loss2 #------------------------add----------------\n",
        "                epoch_loss += loss.item()\n",
        "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
        "\n",
        "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
        "                optimizer.step()\n",
        "\n",
        "                pbar.update(imgs.shape[0])\n",
        "                global_step += 1\n",
        "                # if global_step % (len(dataset) // (10 * batch_size)) == 0:\n",
        "                #     for tag, value in net.named_parameters():\n",
        "                #         tag = tag.replace('.', '/')\n",
        "                #         writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
        "                #         writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
        "                #     val_score = eval_net(net, val_loader, device)\n",
        "                #     scheduler.step(val_score)\n",
        "                #     writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
        "\n",
        "                #     if net.n_classes > 1:\n",
        "                #         logging.info('Validation cross entropy: {}'.format(val_score))\n",
        "                #         writer.add_scalar('Loss/test', val_score, global_step)\n",
        "                #     else:\n",
        "                #         logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
        "                #         writer.add_scalar('Dice/test', val_score, global_step)\n",
        "\n",
        "                #     writer.add_images('images', imgs, global_step)\n",
        "                #     if net.n_classes == 1:\n",
        "                #         writer.add_images('masks/true', true_masks, global_step)\n",
        "                #         writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
        "\n",
        "        if save_cp:\n",
        "            try:\n",
        "                os.mkdir(dir_checkpoint)\n",
        "                logging.info('Created checkpoint directory')\n",
        "            except OSError:\n",
        "                pass\n",
        "            torch.save(net.state_dict(),\n",
        "                       dir_checkpoint + f'CP_epoch{epoch + 1}.pth')\n",
        "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
        "\n",
        "    writer.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3unl_YZQGz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = UNet(n_channels=3, n_classes=1, bilinear=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sqw9aCdQHVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7dac78c0-d073-49aa-bbef-de1c48d6bf57"
      },
      "source": [
        "from torchsummary import summary\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device=device)\n",
        "summary(net, (3,200,200))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 200, 200]             896\n",
            "       BatchNorm2d-2         [-1, 32, 200, 200]              64\n",
            "              ReLU-3         [-1, 32, 200, 200]               0\n",
            "            Conv2d-4         [-1, 32, 200, 200]           9,248\n",
            "       BatchNorm2d-5         [-1, 32, 200, 200]              64\n",
            "              ReLU-6         [-1, 32, 200, 200]               0\n",
            "        DoubleConv-7         [-1, 32, 200, 200]               0\n",
            "         MaxPool2d-8         [-1, 32, 100, 100]               0\n",
            "            Conv2d-9         [-1, 64, 100, 100]          18,496\n",
            "      BatchNorm2d-10         [-1, 64, 100, 100]             128\n",
            "             ReLU-11         [-1, 64, 100, 100]               0\n",
            "           Conv2d-12         [-1, 64, 100, 100]          36,928\n",
            "      BatchNorm2d-13         [-1, 64, 100, 100]             128\n",
            "             ReLU-14         [-1, 64, 100, 100]               0\n",
            "       DoubleConv-15         [-1, 64, 100, 100]               0\n",
            "             Down-16         [-1, 64, 100, 100]               0\n",
            "        MaxPool2d-17           [-1, 64, 50, 50]               0\n",
            "           Conv2d-18          [-1, 128, 50, 50]          73,856\n",
            "      BatchNorm2d-19          [-1, 128, 50, 50]             256\n",
            "             ReLU-20          [-1, 128, 50, 50]               0\n",
            "           Conv2d-21          [-1, 128, 50, 50]         147,584\n",
            "      BatchNorm2d-22          [-1, 128, 50, 50]             256\n",
            "             ReLU-23          [-1, 128, 50, 50]               0\n",
            "       DoubleConv-24          [-1, 128, 50, 50]               0\n",
            "             Down-25          [-1, 128, 50, 50]               0\n",
            "        MaxPool2d-26          [-1, 128, 25, 25]               0\n",
            "           Conv2d-27          [-1, 256, 25, 25]         295,168\n",
            "      BatchNorm2d-28          [-1, 256, 25, 25]             512\n",
            "             ReLU-29          [-1, 256, 25, 25]               0\n",
            "           Conv2d-30          [-1, 256, 25, 25]         590,080\n",
            "      BatchNorm2d-31          [-1, 256, 25, 25]             512\n",
            "             ReLU-32          [-1, 256, 25, 25]               0\n",
            "       DoubleConv-33          [-1, 256, 25, 25]               0\n",
            "             Down-34          [-1, 256, 25, 25]               0\n",
            "        MaxPool2d-35          [-1, 256, 12, 12]               0\n",
            "           Conv2d-36          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-37          [-1, 256, 12, 12]             512\n",
            "             ReLU-38          [-1, 256, 12, 12]               0\n",
            "           Conv2d-39          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-40          [-1, 256, 12, 12]             512\n",
            "             ReLU-41          [-1, 256, 12, 12]               0\n",
            "       DoubleConv-42          [-1, 256, 12, 12]               0\n",
            "             Down-43          [-1, 256, 12, 12]               0\n",
            "         Upsample-44          [-1, 256, 24, 24]               0\n",
            "           Conv2d-45          [-1, 256, 25, 25]       1,179,904\n",
            "      BatchNorm2d-46          [-1, 256, 25, 25]             512\n",
            "             ReLU-47          [-1, 256, 25, 25]               0\n",
            "           Conv2d-48          [-1, 128, 25, 25]         295,040\n",
            "      BatchNorm2d-49          [-1, 128, 25, 25]             256\n",
            "             ReLU-50          [-1, 128, 25, 25]               0\n",
            "       DoubleConv-51          [-1, 128, 25, 25]               0\n",
            "               Up-52          [-1, 128, 25, 25]               0\n",
            "         Upsample-53          [-1, 128, 50, 50]               0\n",
            "           Conv2d-54          [-1, 128, 50, 50]         295,040\n",
            "      BatchNorm2d-55          [-1, 128, 50, 50]             256\n",
            "             ReLU-56          [-1, 128, 50, 50]               0\n",
            "           Conv2d-57           [-1, 64, 50, 50]          73,792\n",
            "      BatchNorm2d-58           [-1, 64, 50, 50]             128\n",
            "             ReLU-59           [-1, 64, 50, 50]               0\n",
            "       DoubleConv-60           [-1, 64, 50, 50]               0\n",
            "               Up-61           [-1, 64, 50, 50]               0\n",
            "         Upsample-62         [-1, 64, 100, 100]               0\n",
            "           Conv2d-63         [-1, 64, 100, 100]          73,792\n",
            "      BatchNorm2d-64         [-1, 64, 100, 100]             128\n",
            "             ReLU-65         [-1, 64, 100, 100]               0\n",
            "           Conv2d-66         [-1, 32, 100, 100]          18,464\n",
            "      BatchNorm2d-67         [-1, 32, 100, 100]              64\n",
            "             ReLU-68         [-1, 32, 100, 100]               0\n",
            "       DoubleConv-69         [-1, 32, 100, 100]               0\n",
            "               Up-70         [-1, 32, 100, 100]               0\n",
            "         Upsample-71         [-1, 32, 200, 200]               0\n",
            "           Conv2d-72         [-1, 32, 200, 200]          18,464\n",
            "      BatchNorm2d-73         [-1, 32, 200, 200]              64\n",
            "             ReLU-74         [-1, 32, 200, 200]               0\n",
            "           Conv2d-75         [-1, 32, 200, 200]           9,248\n",
            "      BatchNorm2d-76         [-1, 32, 200, 200]              64\n",
            "             ReLU-77         [-1, 32, 200, 200]               0\n",
            "       DoubleConv-78         [-1, 32, 200, 200]               0\n",
            "               Up-79         [-1, 32, 200, 200]               0\n",
            "           Conv2d-80          [-1, 1, 200, 200]              33\n",
            "          OutConv-81          [-1, 1, 200, 200]               0\n",
            "================================================================\n",
            "Total params: 4,320,609\n",
            "Trainable params: 4,320,609\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.46\n",
            "Forward/backward pass size (MB): 287.47\n",
            "Params size (MB): 16.48\n",
            "Estimated Total Size (MB): 304.41\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOogjh1fQtf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "917c6d7e-1ec5-45d7-8e4e-ad4cbc321310"
      },
      "source": [
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
        "\n",
        "logging.info(f'Using device {device}')\n",
        "\n",
        "# Change here to adapt to your data\n",
        "# n_channels=3 for RGB images\n",
        "# n_classes is the number of probabilities you want to get per pixel\n",
        "#   - For 1 class and background, use n_classes=1\n",
        "#   - For 2 classes, use n_classes=1\n",
        "#   - For N > 2 classes, use n_classes=N\n",
        "\n",
        "logging.info(f'Network:\\n'\n",
        "              f'\\t{net.n_channels} input channels\\n'\n",
        "              f'\\t{net.n_classes} output channels (classes)\\n'\n",
        "              f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
        "\n",
        "\n",
        "# faster convolutions, but more memorycudnn.benchmark = True\n",
        "train_net(net=net,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          lr=0.001,\n",
        "          device=device,\n",
        "          img_scale=1.0,\n",
        "          val_percent= 10.0/ 100)\n",
        "# except KeyboardInterrupt:\n",
        "#     torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
        "#     logging.info('Saved interrupt')\n",
        "#     try:\n",
        "#         sys.exit(0)\n",
        "#     except SystemExit:\n",
        "#         os._exit(0)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Using device cuda\n",
            "INFO: Network:\n",
            "\t3 input channels\n",
            "\t1 output channels (classes)\n",
            "\tBilinear upscaling\n",
            "INFO: Starting training:\n",
            "        Epochs:          10\n",
            "        Batch size:      32\n",
            "        Learning rate:   0.001\n",
            "        Training size:   9000\n",
            "        Validation size: 1000\n",
            "        Checkpoints:     True\n",
            "        Device:          cuda\n",
            "        Images scaling:  1.0\n",
            "    \n",
            "Epoch 1/10: 100%|██████████| 9000/9000 [03:58<00:00, 37.72img/s, loss (batch)=0.583]\n",
            "INFO: Created checkpoint directory\n",
            "INFO: Checkpoint 1 saved !\n",
            "Epoch 2/10: 100%|██████████| 9000/9000 [03:53<00:00, 38.58img/s, loss (batch)=0.562]\n",
            "INFO: Checkpoint 2 saved !\n",
            "Epoch 3/10: 100%|██████████| 9000/9000 [03:53<00:00, 38.61img/s, loss (batch)=0.55]\n",
            "INFO: Checkpoint 3 saved !\n",
            "Epoch 4/10: 100%|██████████| 9000/9000 [03:52<00:00, 38.64img/s, loss (batch)=0.593]\n",
            "INFO: Checkpoint 4 saved !\n",
            "Epoch 5/10: 100%|██████████| 9000/9000 [03:52<00:00, 38.66img/s, loss (batch)=0.574]\n",
            "INFO: Checkpoint 5 saved !\n",
            "Epoch 6/10: 100%|██████████| 9000/9000 [03:52<00:00, 38.71img/s, loss (batch)=0.529]\n",
            "INFO: Checkpoint 6 saved !\n",
            "Epoch 7/10: 100%|██████████| 9000/9000 [03:52<00:00, 38.68img/s, loss (batch)=0.573]\n",
            "INFO: Checkpoint 7 saved !\n",
            "Epoch 8/10: 100%|██████████| 9000/9000 [03:52<00:00, 38.77img/s, loss (batch)=0.537]\n",
            "INFO: Checkpoint 8 saved !\n",
            "Epoch 9/10: 100%|██████████| 9000/9000 [03:52<00:00, 38.74img/s, loss (batch)=0.55]\n",
            "INFO: Checkpoint 9 saved !\n",
            "Epoch 10/10: 100%|██████████| 9000/9000 [03:52<00:00, 38.77img/s, loss (batch)=0.583]\n",
            "INFO: Checkpoint 10 saved !\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK4f4lLvOenE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp checkpoints/*.pth '/content/drive/My Drive/Untitled folder/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8e20Hc_VdM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "0b27f534-2597-4690-dab4-6eaceec54f97"
      },
      "source": [
        "del net"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1ba45ac6a5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmLcPPYcG4Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf sample50/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYDQzdmw7GwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir sample50\n",
        "!mkdir sample50/out\n",
        "!mkdir sample50/ind\n",
        "!mkdir sample50/act\n",
        "from predict import *\n",
        "from PIL import Image\n",
        "sdir = 'sample50/out/'\n",
        "actdir ='sample50/act/'\n",
        "indir ='sample50/ind/'\n",
        "for i,idx in enumerate(os.listdir('data/fgbg/')):\n",
        "  if i==100:\n",
        "    break;\n",
        "  img = Image.open('data/fgbg/'+idx)\n",
        "  img.save(indir+idx)\n",
        "  act = Image.open('data/depth/'+idx)\n",
        "  act.save(actdir+idx)\n",
        "  mask = predict_img(net=net, full_img=img, scale_factor=1.0, out_threshold=0.1, device=device)\n",
        "  result = mask_to_image(mask)\n",
        "  result.save(sdir+idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9nQUfwVVOS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir sample50/out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al-BSZjzC03W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from PIL import Image \n",
        "from predict import predict_img\n",
        "from matplotlib import cm\n",
        "import matplotlib\n",
        "net = UNet(3, 1).cuda()\n",
        "dire = 'sample50/fgbg/'\n",
        "sdir = 'sample50/out/'\n",
        "sdir = ''\n",
        "lst_msk = []\n",
        "net.load_state_dict(torch.load('/content/drive/My Drive/models/CP_epoch1.pth'))\n",
        "for i,dx in enumerate(listdir(dire)):\n",
        "  img = Image.open(dire+dx)\n",
        "  mask = predict_img(net, img, device)\n",
        "  matplotlib.image.imsave(sdir+dx, mask)\n",
        "  #im.save(sdir+dx)\n",
        "  lst_msk.append(mask)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgwkHi5lKaaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e150dcd-3bd9-40c9-a616-227f1e9312a8"
      },
      "source": [
        "len(lst_msk)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZBuJqw9Dhfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "!mkdir sample10k\n",
        "!mkdir sample10k/fgbg\n",
        "!mkdir sample10k/depth\n",
        "!mkdir sample10k/mask\n",
        "!mkdir sample50\n",
        "!mkdir sample50/fgbg\n",
        "!mkdir sample50/depth\n",
        "!mkdir sample50/mask\n",
        "rootsrc = 'data/'\n",
        "import os\n",
        "for i,idx in enumerate(os.listdir(rootsrc+'fgbg/')):\n",
        "  if( i == 10000):\n",
        "    break\n",
        "  shutil.copy(rootsrc + 'fgbg/' + idx, 'sample10k/fgbg/') \n",
        "  shutil.copy(rootsrc + 'fgbgmask/' + idx, 'sample10k/mask/') \n",
        "  shutil.copy(rootsrc + 'Depthmap/' + idx, 'sample10k/depth/') \n",
        "  if (i<50):\n",
        "    shutil.copy(rootsrc + 'fgbg/' + idx, 'sample50/fgbg/') \n",
        "    shutil.copy(rootsrc + 'fgbgmask/' + idx, 'sample50/mask/') \n",
        "    shutil.copy(rootsrc + 'Depthmap/' + idx, 'sample50/depth/') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEhJzMC9NJI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r sample50 '/content/drive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOjX-T1fNsAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile \n",
        "import os \n",
        "  \n",
        "def get_all_file_paths(directory): \n",
        "  \n",
        "    # initializing empty file paths list \n",
        "    file_paths = [] \n",
        "  \n",
        "    # crawling through directory and subdirectories \n",
        "    for root, directories, files in os.walk(directory): \n",
        "        for filename in files: \n",
        "            # join the two strings in order to form the full filepath. \n",
        "            filepath = os.path.join(root, filename) \n",
        "            file_paths.append(filepath) \n",
        "  \n",
        "    # returning all file paths \n",
        "    return file_paths         \n",
        "  \n",
        "def main(): \n",
        "    # path to folder which needs to be zipped \n",
        "    directory = 'sample10k/'\n",
        "  \n",
        "    # calling function to get all file paths in the directory \n",
        "    file_paths = get_all_file_paths(directory) \n",
        "  \n",
        "    # printing the list of all files to be zipped \n",
        "    print('Following files will be zipped:') \n",
        "    for file_name in file_paths: \n",
        "        print(file_name) \n",
        "  \n",
        "    # writing files to a zipfile \n",
        "    with ZipFile('sample10.zip','w') as zip: \n",
        "        # writing each file one by one \n",
        "        for file in file_paths: \n",
        "            zip.write(file) \n",
        "  \n",
        "    print('All files zipped successfully!')  \n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3oxkK1hPHVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp sample10.zip '/content/drive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}